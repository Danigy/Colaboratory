{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Neural network-based singing voice synthesis demo using kiritan_singing database (Japanese).ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [
        "VWhj3SHGRShX"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOi40QwOl8FHzLkwHYwmsUP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/r9y9/Colaboratory/blob/master/Neural_network_based_singing_voice_synthesis_demo_using_kiritan_singing_database_(Japanese).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQjZmX2nQLfR",
        "colab_type": "text"
      },
      "source": [
        "# Neural network-based singing voice synthesis demo using kiritan_singing database (Japanese)\n",
        "\n",
        "This is a demo of a singing voice synthesis system trained on the [kiritan_singing database (*Japanese*)](https://zunko.jp/kiridev/login.php). Given a musicxml file, the system generates waveform.\n",
        "\n",
        "All the models were trained using https://github.com/r9y9/nnsvs/. Recipes to reproduce experiments are included in the repository: https://github.com/r9y9/nnsvs/tree/master/egs/kiritan_singing.\n",
        "\n",
        "Estimate time to run: 5 mins.\n",
        "\n",
        "\n",
        "## Notice\n",
        "\n",
        "This is an alpha version of demo and singing voice quality is not very high (this is expected). Major updates and improvements are comming soon. More details on this project can be found at https://github.com/r9y9/nnsvs/issues/1."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oi7WL3T1-H9w",
        "colab_type": "text"
      },
      "source": [
        "## Download music xml files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t4UVgGL4-aOv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! git clone -q https://github.com/r9y9/kiritan_singing"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VWhj3SHGRShX",
        "colab_type": "text"
      },
      "source": [
        "## Install requirements\n",
        "\n",
        "At the moment, nnsvs depends on sinsy (C++ library) for the muxicxml to context feature conversion. Installing binary dependencies is a bit complicated, but here goes the complete setup."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BzyX0v8HRrCS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! pip install -q -U numpy cython\n",
        "! rm -rf hts_engine_API sinsy pysinsy nnmnkwii nnsvs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bh5_HHAdPyUA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Binary dependencies\n",
        "! git clone -q https://github.com/r9y9/hts_engine_API\n",
        "! cd hts_engine_API/src && ./waf configure --prefix=/usr/ && sudo ./waf build > /dev/null 2>&1 && ./waf install\n",
        "! git clone -q https://github.com/r9y9/sinsy\n",
        "! cd sinsy/src/ && mkdir -p build && cd build && cmake -DCMAKE_BUILD_TYPE=Release -DBUILD_SHARED_LIBS=ON -DCMAKE_INSTALL_PREFIX=/usr/ .. && make -j > /dev/null 2>&1 && sudo make install\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VACHstV2RjAm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Python dependencies\n",
        "! git clone -q https://github.com/r9y9/pysinsy\n",
        "! cd pysinsy && export SINSY_INSTALL_PREFIX=/usr/ && pip install -q .\n",
        "! git clone -q https://github.com/r9y9/nnmnkwii\n",
        "! cd nnmnkwii && pip install -q .\n",
        "! git clone -q https://github.com/r9y9/nnsvs \n",
        "! cd nnsvs && pip install -q ."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3p5KDOHy8OnC",
        "colab_type": "text"
      },
      "source": [
        "## Python imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FgpDInEI0tVS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%pylab inline\n",
        "rcParams[\"figure.figsize\"] = (16,5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qX8FC_XlSPlh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import hydra\n",
        "from omegaconf import DictConfig, OmegaConf\n",
        "import numpy as np\n",
        "import joblib\n",
        "import torch\n",
        "from os.path import join, basename, exists\n",
        "import os\n",
        "import pysptk\n",
        "import pyworld\n",
        "import librosa\n",
        "import librosa.display\n",
        "import IPython\n",
        "from IPython.display import Audio\n",
        "from nnmnkwii.io import hts\n",
        "from nnmnkwii import paramgen\n",
        "from nnmnkwii.preprocessing.f0 import interp1d\n",
        "from nnmnkwii.frontend import merlin as fe\n",
        "\n",
        "from nnsvs.multistream import multi_stream_mlpg, split_streams\n",
        "from nnsvs.gen import (\n",
        "    predict_timelag, predict_duration, predict_acoustic, postprocess_duration,\n",
        "    gen_waveform, get_windows)\n",
        "from nnsvs.frontend.ja import xml2lab, _lazy_init\n",
        "from nnsvs.gen import _midi_to_hz\n",
        "\n",
        "_lazy_init(dic_dir=\"/usr/lib/sinsy/dic\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "03R6EYp4ULok",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample_rate = 48000\n",
        "frame_period = 5\n",
        "fftlen = pyworld.get_cheaptrick_fft_size(sample_rate)\n",
        "alpha = pysptk.util.mcepalpha(sample_rate)\n",
        "hop_length = int(0.001 * frame_period * sample_rate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LdCvZzUt0xPy",
        "colab_type": "text"
      },
      "source": [
        "## Setup models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4lfMonh6Vi2z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! curl -q -LO https://www.dropbox.com/s/pctlausq00eecqp/20200502_kiritan_singing-00-svs-world.zip\n",
        "! unzip -qq -o 20200502_kiritan_singing-00-svs-world.zip\n",
        "\n",
        "model_dir = \"./20200502_kiritan_singing-00-svs-world\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jTnJXxz4VjZu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "use_cuda = True\n",
        "if use_cuda and torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZSluQysG06pZ",
        "colab_type": "text"
      },
      "source": [
        "### Time-lag model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RvS-2DXxZ5SI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "timelag_config = OmegaConf.load(join(model_dir, \"timelag\", \"model.yaml\"))\n",
        "timelag_model = hydra.utils.instantiate(timelag_config.netG).to(device)\n",
        "checkpoint = torch.load(join(model_dir, \"timelag\", \"latest.pth\"), map_location=lambda storage, loc: storage)\n",
        "timelag_model.load_state_dict(checkpoint[\"state_dict\"])\n",
        "timelag_in_scaler = joblib.load(join(model_dir, \"in_timelag_scaler.joblib\"))\n",
        "timelag_out_scaler = joblib.load(join(model_dir, \"out_timelag_scaler.joblib\"))\n",
        "timelag_model.eval();"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3VoPGoAR3kpV",
        "colab_type": "text"
      },
      "source": [
        "### Duration model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pl8Q5DgP1eIg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "duration_config = OmegaConf.load(join(model_dir, \"duration\", \"model.yaml\"))\n",
        "duration_model = hydra.utils.instantiate(duration_config.netG).to(device)\n",
        "checkpoint = torch.load(join(model_dir, \"duration\", \"latest.pth\"), map_location=lambda storage, loc: storage)\n",
        "duration_model.load_state_dict(checkpoint[\"state_dict\"])\n",
        "duration_in_scaler = joblib.load(join(model_dir, \"in_duration_scaler.joblib\"))\n",
        "duration_out_scaler = joblib.load(join(model_dir, \"out_duration_scaler.joblib\"))\n",
        "duration_model.eval();"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O2flghYb3q-o",
        "colab_type": "text"
      },
      "source": [
        "### Acoustic model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bwmBKAE83pYG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "acoustic_config = OmegaConf.load(join(model_dir, \"acoustic\", \"model.yaml\"))\n",
        "acoustic_model = hydra.utils.instantiate(acoustic_config.netG).to(device)\n",
        "checkpoint = torch.load(join(model_dir, \"acoustic\", \"latest.pth\"), map_location=lambda storage, loc: storage)\n",
        "acoustic_model.load_state_dict(checkpoint[\"state_dict\"])\n",
        "acoustic_in_scaler = joblib.load(join(model_dir, \"in_acoustic_scaler.joblib\"))\n",
        "acoustic_out_scaler = joblib.load(join(model_dir, \"out_acoustic_scaler.joblib\"))\n",
        "acoustic_model.eval();"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "omkQ2G4i4DZN",
        "colab_type": "text"
      },
      "source": [
        "## Synthesis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7b9Yc05CQSu",
        "colab_type": "text"
      },
      "source": [
        "### Choose your favorite musicxml file here!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_V1yQdEe4MTq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# NOTE: 01.xml and 02.xml were not included in the training data\n",
        "# 03.xml - 37.xml were used for training.\n",
        "labels = xml2lab(\"kiritan_singing/musicxml/01.xml\").round_()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-HvucB14TFS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "question_path = join(model_dir, \"jp_qst001_nnsvs.hed\")\n",
        "binary_dict, continuous_dict = hts.load_question_set(question_path, append_hat_for_LL=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q8yAgiw36fCZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# pitch indices in the input features\n",
        "pitch_idx = len(binary_dict) + 1\n",
        "pitch_indices = np.arange(len(binary_dict), len(binary_dict)+3)\n",
        "log_f0_conditioning = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4q5INSdh6lVj",
        "colab_type": "text"
      },
      "source": [
        "### Predict time-lag"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXzv451B6jS6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lag = predict_timelag(device, labels, timelag_model, timelag_in_scaler,\n",
        "    timelag_out_scaler, binary_dict, continuous_dict, pitch_indices,\n",
        "    log_f0_conditioning)\n",
        "lag.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EQr9u_uv6lzg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot(lag / 50000, label=\"Timelag (in frames) for note onsets\", linewidth=2)\n",
        "xlabel(\"Time index in musical note\")\n",
        "ylabel(\"Timelag\")\n",
        "legend();"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9OALA70D6sHy",
        "colab_type": "text"
      },
      "source": [
        "### Predict phoneme durations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gffqkEYU6o5F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "durations = predict_duration(device, labels, duration_model,\n",
        "    duration_in_scaler, duration_out_scaler, lag, binary_dict, continuous_dict,\n",
        "    pitch_indices, log_f0_conditioning)\n",
        "durations.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QnoRw3Ah6tX1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot(durations, label=\"Phoneme durations in frames\")\n",
        "xlabel(\"Time index in phone\")\n",
        "ylabel(\"Duration\")\n",
        "legend();"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oIBV5ZJj6xPv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Normalize phoneme durations to satisfy constraints by the musical score\n",
        "duration_modified_labels = postprocess_duration(labels, durations, lag)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C0_rgqQg6v77",
        "colab_type": "text"
      },
      "source": [
        "### Predict acoustic features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WAuA45p26uP_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "acoustic_features = predict_acoustic(device, duration_modified_labels, acoustic_model,\n",
        "    acoustic_in_scaler, acoustic_out_scaler, binary_dict, continuous_dict,\n",
        "    \"coarse_coding\", pitch_indices, log_f0_conditioning)\n",
        "acoustic_features.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R0dkvEJK6318",
        "colab_type": "text"
      },
      "source": [
        "### Visualize acoustic features\n",
        "\n",
        "Before generating a wavefrom, let's visualize acoustic features to understand how the acoustic model works. Since acoustic features contain multiple differnt features (*multi-stream*, e.g., mgc, lf0, vuv and bap), let us first split acoustic features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "coYE3tqF61tQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stream_sizes = acoustic_config.stream_sizes\n",
        "has_dynamic_features = acoustic_config.has_dynamic_features\n",
        "# (mgc, lf0, vuv, bap) with delta and delta-delta except for vuv\n",
        "stream_sizes, has_dynamic_features"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LuCrC7GY65Ls",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "feats = multi_stream_mlpg(\n",
        "    acoustic_features, acoustic_out_scaler.var_, get_windows(3), stream_sizes,\n",
        "    has_dynamic_features)\n",
        "# get static features\n",
        "mgc, diff_lf0, vuv, bap = split_streams(feats, [60, 1, 1, 5])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ma-6HPn068Kb",
        "colab_type": "text"
      },
      "source": [
        "#### Visualize F0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0OPYJoT6511",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# relative f0 -> absolute f0\n",
        "# need to extract pitch sequence from the musical score\n",
        "linguistic_features = fe.linguistic_features(duration_modified_labels,\n",
        "                                            binary_dict, continuous_dict,\n",
        "                                            add_frame_features=True,\n",
        "                                            subphone_features=\"coarse_coding\")\n",
        "f0_score = _midi_to_hz(linguistic_features, pitch_idx, False)[:, None]\n",
        "lf0_score = f0_score.copy()\n",
        "nonzero_indices = np.nonzero(lf0_score)\n",
        "lf0_score[nonzero_indices] = np.log(f0_score[nonzero_indices])\n",
        "lf0_score = interp1d(lf0_score, kind=\"slinear\")\n",
        "\n",
        "f0 = diff_lf0 + lf0_score\n",
        "f0[vuv < 0.5] = 0\n",
        "f0[np.nonzero(f0)] = np.exp(f0[np.nonzero(f0)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dwqgIQfp69QJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot(f0[-2500:, :], linewidth=2, label=\"F0 contour (in Hz)\")\n",
        "plot((vuv[-2500:, :] > 0.5)*100, linewidth=2, label=\"Voiced/unvoiced flag\")\n",
        "legend()\n",
        "xlabel(\"Frame\")\n",
        "ylabel(\"F0 (in Hz)\");"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "smlsejRv7ByF",
        "colab_type": "text"
      },
      "source": [
        "#### Visualize spectrogram"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mdsyUi3u6-Rt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Trim and visualize (to save memory and time)\n",
        "logsp = np.log(pysptk.mc2sp(mgc[-2500:, :], alpha=alpha, fftlen=fftlen))\n",
        "librosa.display.specshow(logsp.T, sr=sample_rate, hop_length=hop_length, x_axis=\"time\", y_axis=\"linear\", cmap=\"jet\");"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GpnhK_Um7FPX",
        "colab_type": "text"
      },
      "source": [
        "#### Visualize aperiodicity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OUCWh5Er7DAU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "aperiodicity = pyworld.decode_aperiodicity(bap[-2500:, :].astype(np.float64), sample_rate, fftlen)\n",
        "librosa.display.specshow(aperiodicity.T, sr=sample_rate, hop_length=hop_length, x_axis=\"time\", y_axis=\"linear\", cmap=\"jet\");"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_i8cFqle7Ibm",
        "colab_type": "text"
      },
      "source": [
        "### Generate waveform\n",
        "\n",
        "Finally, let's generate waveform and listen to the sample."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BLMUQa2c7Gei",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "generated_waveform = gen_waveform(\n",
        "    duration_modified_labels, acoustic_features, acoustic_out_scaler,\n",
        "    binary_dict, continuous_dict, acoustic_config.stream_sizes,\n",
        "    acoustic_config.has_dynamic_features,\n",
        "    \"coarse_coding\", log_f0_conditioning,\n",
        "    pitch_idx, num_windows=3,\n",
        "    post_filter=True, sample_rate=sample_rate, frame_period=frame_period,\n",
        "    relative_f0=True)\n",
        "\n",
        "# trim trailing/leading silences for covenience\n",
        "generated_waveform = librosa.effects.trim(generated_waveform)[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XYSyTQylDvIR",
        "colab_type": "text"
      },
      "source": [
        "## Listen to the generated sample"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-qNFhnu7J1T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "librosa.display.waveplot(generated_waveform, sample_rate, x_axis=\"time\")\n",
        "IPython.display.display(Audio(generated_waveform, rate=sample_rate))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5a2Q8N487MPZ",
        "colab_type": "text"
      },
      "source": [
        "## Summary\n",
        "\n",
        "A demo of a singing voice synthesis system based on neural networks. Full code is available https://github.com/r9y9/nnsvs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5XQ_diETC6FB",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "## References\n",
        "\n",
        "- Kiritan database: https://zunko.jp/kiridev/login.php\n",
        "- Code to reproduce: https://github.com/r9y9/nnsvs"
      ]
    }
  ]
}